{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d94868-eb03-4189-af1d-ed24089dff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data0/lsst_stack/stack/miniconda3-py38_4.9.2-0.4.2/Linux64/sims_maf/2.13.0.sims-93-g8bc2eb33+a14e41332a/python/lsst/sims/maf/db/opsimDatabase.py:95: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if groupBy is 'default' and tableName==self.defaultTable:\n",
      "/data0/lsst_stack/stack/miniconda3-py38_4.9.2-0.4.2/Linux64/sims_maf/2.13.0.sims-93-g8bc2eb33+a14e41332a/python/lsst/sims/maf/db/opsimDatabase.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if groupBy is 'default' and tableName!=self.defaultTable:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, time, glob, pickle\n",
    "from tqdm import tqdm\n",
    "from utils_opsim import *\n",
    "#lsst modules\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.plots as plots\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "from lsst.sims.maf.metrics import BaseMetric\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "from lsst.sims.photUtils import Dust_values\n",
    "from lsst.sims.photUtils import Bandpass, SignalToNoise, PhotometricParameters, calcMagError_m5, calcGamma\n",
    "from lsst.sims.utils import uniformSphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6bc99f-0d49-45c7-8e5e-ab93448f97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568a555-5a0d-4e53-a53a-e3dee9e4a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is needed only the very first time when the simulated lightcurves have to be imported on the platform\n",
    "#with zipfile.ZipFile('./True Novelties/kn_newmodel_Alberto.zip', \"r\") as z:\n",
    "#      z.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911e6382-f3f2-40b0-9d07-f4f12825465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = glob.glob('./kn_newmodel_Alberto/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c674bf8a-c4c9-480b-81f3-354cfd788b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GRBKN_obs(metrics.BaseMetric):\n",
    "    \"\"\"\n",
    "        Class object, observed lightcurve from LSST observing constraints\n",
    "        Parameters\n",
    "        ------------\n",
    "            mjdCol= MJD observations column name from Opsim database      (DEFAULT = observationStartMJD) \n",
    "            m5Col= Magnitude limit column name from Opsim database      (DEFAULT = fiveSigmaDepth)\n",
    "            filterCol= Filters column name from Opsim database      (DEFAULT = filter)\n",
    "            exptimeCol = Column name for the total exposure time of the visit(DEFAULT = visitExposureTime)\n",
    "            nightCol = The night's column of the survey (starting at 1) (DEFAULT = night)\n",
    "            vistimeCol = Column name for the total time of the visit (DEFAULT = visitTime)\n",
    "            RACol= RA column name from Opsim database      (DEFAULT = fieldRA)\n",
    "            DecCol= Dec column name from Opsim database      (DEFAULT = fieldDec)\n",
    "            surveyduration= Survey Duration      (DEFAULT = 10)\n",
    "            mjd0= Survey start date      (DEFAULT = 59853.5)\n",
    "            Filter_selection = \n",
    "        Returns\n",
    "        -------\n",
    "            nobj: number of detected lightcurves\n",
    "            csv files with the observed lightcurves\n",
    "        \"\"\"\n",
    "    def read_lightCurve(self, file):\n",
    "        \"\"\"Reads in a csv file, from the simulated ligh curves, time and mag columns for each filter\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            The data read from the ascii text file, in a numpy structured array with columns\n",
    "            'ph' (phase / epoch, in days), 'mag' (magnitude), 'flt' (filter for the magnitude).\n",
    "        \"\"\"\n",
    "        time = np.arange(0.5, 20 + 0.5, 0.5)\n",
    "        ll = pd.DataFrame(file, columns=['file_paths'])\n",
    "        ll['lc']=ll['file_paths'].apply(lambda x: pd.read_csv(x, index_col=False))\n",
    "        ll['transDuration'] = ll['lc'].apply(lambda x: time.max() - time.min())\n",
    "        ll['T0'] = ll['lc'].apply(lambda x: time.min())\n",
    "        return ll\n",
    "    \n",
    "    def __init__(self, metricName='GRBKN_obs', mjdCol='observationStartMJD', \n",
    "                 RACol='fieldRA', DecCol='fieldDec',filterCol='filter', m5Col='fiveSigmaDepth', \n",
    "                 exptimeCol='visitExposureTime',nightCol='night',vistimeCol='visitTime', snrlim=5, ptsNeeded=2, dist_Mpc=46.48, mjd0=59853.5,\n",
    "                 data_path='./lc', obs_path='./obs_lc',surveyduration=10,Filter_selection = False,nFilter=1, save=True,**kwargs):\n",
    "        maps = ['DustMap']\n",
    "        self.mjdCol = mjdCol\n",
    "        self.m5Col = m5Col\n",
    "        self.filterCol = filterCol\n",
    "        self.RACol = RACol\n",
    "        self.DecCol = DecCol\n",
    "        self.exptimeCol = exptimeCol\n",
    "        self.nightCol = nightCol\n",
    "        self.vistimeCol = vistimeCol\n",
    "        self.nightCol = nightCol\n",
    "        self.ptsNeeded = ptsNeeded\n",
    "        self.data_path = data_path\n",
    "        self.obs_path = obs_path\n",
    "        self.dist_Mpc = dist_Mpc\n",
    "        self.surveyduration=surveyduration\n",
    "        self.mjd0=mjd0\n",
    "        self.Filter_selection=Filter_selection\n",
    "        self.nFilter=nFilter\n",
    "        self.snrlim = snrlim\n",
    "        self.save = save\n",
    "        if not os.path.exists(self.obs_path):\n",
    "            os.mkdir(self.obs_path)\n",
    "        self.bandpass = Bandpass(wavelen=np.array([480.2,623.1,754.2]),\n",
    "                                 sb=np.array([0.1,0.1,0.1]),wavelen_min=380, wavelen_max=850, wavelen_step=10)\n",
    "        super(GRBKN_obs, self).__init__(col=[self.mjdCol,self.m5Col, self.filterCol,self.RACol,\n",
    "                                                                   self.DecCol,self.exptimeCol,self.nightCol,\n",
    "                                                                   self.vistimeCol],\n",
    "                                                       metricDtype='object', units='',\n",
    "                                                       metricName=metricName, **kwargs)\n",
    "        self.bandpass = Bandpass(wavelen=np.array([480.2,623.1,754.2]),sb=np.array([0.1,0.1,0.1]),wavelen_min=380, wavelen_max=850, wavelen_step=10)\n",
    "        self.photparam = PhotometricParameters() \n",
    "        lcfile = glob.glob(self.data_path+'/*.csv')\n",
    "        lcfile = np.array(self.lcfile).reshape(-1)\n",
    "        self.lcs = self.read_lightCurve(flc)\n",
    "     \n",
    "    def make_lightCurve(self, template, time, filters,transduration):\n",
    "        \"\"\"Turn lightcurve definition into magnitudes at a series of times.\n",
    "        Parameters\n",
    "        ----------\n",
    "        time : numpy.ndarray\n",
    "            The times of the observations.\n",
    "        filters : numpy.ndarray\n",
    "            The filters of the observations.\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "             The magnitudes of the transient at the times and in the filters of the observations.\n",
    "        \"\"\"\n",
    "        flt = np.unique(filters)\n",
    "        lcMags = np.zeros(time.size, dtype=float)\n",
    "        time = (time-self.mjd0)%transduration\n",
    "        for key in set(flt):\n",
    "            # Interpolate the lightcurve template to the times of the observations, in this filter.\n",
    "            temp_ph=np.array(np.logspace(-1,np.log10(30),50),float)#template['time'], float)\n",
    "            lcMags[filters==key] = np.interp(time[filters==key], temp_ph,\n",
    "                                        np.array(template[key], float))\n",
    "        return lcMags\n",
    "    def coadd(self, data):\n",
    "        \"\"\"\n",
    "        Method to coadd data per band and per night\n",
    "        Parameters\n",
    "        ------------\n",
    "        data : `pd.DataFrame`\n",
    "            pandas df of observations\n",
    "        Returns\n",
    "        -------\n",
    "        coadded data : `pd.DataFrame`\n",
    "        \"\"\"\n",
    "\n",
    "        keygroup = [self.filterCol, self.nightCol]\n",
    "\n",
    "        data.sort_values(by=keygroup, ascending=[\n",
    "                         True, True], inplace=True)\n",
    "\n",
    "        coadd_df = data.groupby(keygroup).agg({self.vistimeCol: ['sum'],\n",
    "                                               self.exptimeCol: ['sum'],\n",
    "                                               self.mjdCol: ['mean'],\n",
    "                                               self.RACol: ['mean'],\n",
    "                                               self.DecCol: ['mean'],\n",
    "                                               self.m5Col: ['mean']}).reset_index()\n",
    "\n",
    "        coadd_df.columns = [self.filterCol, self.nightCol, \n",
    "                            self.vistimeCol, self.exptimeCol, self.mjdCol,\n",
    "                            self.RACol, self.DecCol, self.m5Col]\n",
    "\n",
    "        coadd_df.loc[:, self.m5Col] += 1.25 * \\\n",
    "            np.log10(coadd_df[self.vistimeCol]/30.)\n",
    "\n",
    "        coadd_df.sort_values(by=[self.filterCol, self.nightCol], ascending=[\n",
    "                             True, True], inplace=True)\n",
    "\n",
    "        return coadd_df.to_records(index=False)\n",
    "\n",
    "    def name_lc(self, t, lcname, name):\n",
    "        return self.obs_path+'/obs_{}_'.format(name)+lcname+'_T={}.npy'.format(t)\n",
    "    def run(self,dataSlice, slicePoint=None):\n",
    "        # Sort the entire dataSlice in order of time. \n",
    "        dataSlice.sort(order=self.mjdCol)\n",
    "        dataSlice = self.coadd(pd.DataFrame(dataSlice))\n",
    "        \n",
    "        field_idx = np.random.choice(range(np.size(dataSlice[self.RACol])))\n",
    "        Ra, Dec = dataSlice[self.RACol][field_idx],dataSlice[self.DecCol][field_idx]\n",
    "        bandpass = self.bandpass\n",
    "        photparam = self.photparam\n",
    "        calcSNR_m5=np.vectorize(SignalToNoise.calcSNR_m5)\n",
    "        \n",
    "        obs_filter = dataSlice[self.filterCol]\n",
    "        obs = dataSlice[self.mjdCol]       \n",
    "        obs_m5 = dataSlice[self.m5Col]\n",
    "        nobj = np.array([0,0],[('detected','i4'),('undetected','i4')]) \n",
    "        \n",
    "\n",
    "        lcNumberStart = -1 * np.floor((dataSlice[self.mjdCol].min() - self.mjd0) / self.lcs['transDuration'].to_numpy()[:,None])\n",
    "        # Calculate the time/epoch for each lightcurve.\n",
    "        lcEpoch = (obs-self.mjd0) % self.lcs['transDuration'].to_numpy()[:,None]\n",
    "        # Identify the observations which belong to each distinct light curve.\n",
    "        lcNumber = np.floor((obs-self.mjd0 )  / lcs['transDuration'].to_numpy()[:,None]) + lcNumberStart\n",
    "        lcNumberStart = lcNumber.max(axis=0)\n",
    "        ulcNumber = np.array(list(map(np.unique,lcNumber)))\n",
    "        lcLeft = np.array([np.searchsorted(lcNumber[i,:], ulcNumber[i,:], side='left')for i in range(ulcNumber.shape[0])])\n",
    "        lcRight = np.array([np.searchsorted(lcNumber[i,:], ulcNumber[i,:], side='right')for i in range(ulcNumber.shape[0])])\n",
    "        self.lcs['obs'] = self.lcs.apply(lambda x: self.make_lightCurve(x['lc'],obs, obs_filter,x['transDuration']), axis=1)\n",
    "        lcMag = np.array(self.lcs['obs'].tolist())  + 5*np.log10(self.dist_Mpc*10**6)-5\n",
    "        gamma = np.array([calcGamma(self.bandpass, m, self.photparam) \n",
    "                          for m in obs_m5])\n",
    "\n",
    "        merr, _= calcMagError_m5(lcMag, bandpass, obs_m5,\n",
    "                                    photparam, gamma=gamma)\n",
    "        #lcSNR,_ = calcSNR_m5(lcMag, bandpass, obs_m5, photparam)\n",
    "        lcpoints_AboveThresh = np.zeros(np.shape(lcMag), dtype=bool) \n",
    "        for f in np.unique(obs_filter):                    \n",
    "            filtermatch = np.where(obs_filter == f)\n",
    "            lcpoints_AboveThresh[:,filtermatch] = np.where(lcMag[:,filtermatch] <= obs_m5[filtermatch],True,lcpoints_AboveThresh[:,filtermatch])\n",
    "        T0 = lcs['T0'][:,None] + self.mjd0 + ulcNumber*lcs['transDuration'].to_numpy()[:,None]\n",
    "\n",
    "        #INITIALIZATION 10yrs LCs\n",
    "        detection_map = np.array([[lcpoints_AboveThresh[i,init:end] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc))],dtype=object)\n",
    "        lcEpochs= np.array([[lcEpoch[i,init:end] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc)) ],dtype=object)\n",
    "        lcMags = np.array([[lcMag[i,init:end] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc)) ],dtype=object)\n",
    "        lcMerr = np.array([[merr[i,init:end] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc)) ],dtype=object)\n",
    "        lcfilters = np.array([[obs_filter[init:end] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc)) ],dtype=object)\n",
    "        lcmaglim = np.array([[obs_m5[init:end] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc)) ],dtype=object)\n",
    "\n",
    "        Dpoints = np.array([[np.sum(detections, axis= 0) for detections in detection_map[i]] for i in range(len(flc))])  #counts the number of detected points\n",
    "        nobj['detected']=np.sum([points>self.ptsNeeded for i in range(len(flc))  for points in Dpoints[i] ])\n",
    "        nobj['undetected']=np.sum([points>self.ptsNeeded for i in range(len(flc))  for points in Dpoints[i] ])\n",
    "        if self.save:\n",
    "            shift = np.array([[ulcNumber[i,j]*lcs['transDuration'][i] for j,(init,end) in enumerate(zip(lcLeft[i,:],lcRight[i,:])) if init!= end]for i in range(len(flc)) ])\n",
    "            epochs = lcEpochs +  self.mjd0 + shift\n",
    "\n",
    "            total_lc = np.dstack([epochs,\n",
    "                    lcfilters,\n",
    "                    lcMags,\n",
    "                    lcMerr,\n",
    "                    lcmaglim,\n",
    "                    detection_map])\n",
    "\n",
    "            name_ = np.vectorize(self.name_lc)\n",
    "            names = name_(T0,\n",
    "                          np.repeat(np.array(flc)[:,None],ulcNumber.shape[1],axis=0).reshape(ulcNumber.shape),\n",
    "                          ulcNumber)\n",
    "            names = np.expand_dims(names, axis=-1)\n",
    "            out = list(zip(names,total_lc))\n",
    "            with open(self.obs_path+'/simRA={}_DEC={}_part{}.pkl'.format(np.round(Ra,2),np.round(Dec,2), nflc+1), 'wb') as outfile:\n",
    "                pickle.dump(out, outfile)\n",
    "            ndet = np.sum(Dpoints)\n",
    "            res = ndet/nobj['detected'][0]/6\n",
    "            print(res)\n",
    "        else:\n",
    "            ndet = np.sum(Dpoints)\n",
    "            res = ndet/nobj['detected'][0]/6\n",
    "            print(res)\n",
    "        return res\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361dec00-5177-4616-a7b8-d1c4553acce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbs = glob.glob('/sims_maf/fbs_2.0/*')\n",
    "dbDir = '/sims_maf/fbs_2.0/*'\n",
    "outDir = './nmma_lsst_outputv2.00_newmodel_pop'\n",
    "resultsDb = db.ResultsDb(outDir=outDir)\n",
    "db_folders=glob.glob(dbDir+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de8bb72-993d-4e5a-b714-b72e075066fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_f= np.vectorize(os.path.isdir)\n",
    "glob_f = np.vectorize(glob.glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e143e9a6-65c6-4608-9b8f-8cef225b4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbases = []\n",
    "for folder in db_folders:\n",
    "     if os.path.isdir(folder):\n",
    "        for sub in glob.glob(folder+'/*'):\n",
    "            if os.path.isdir(sub):\n",
    "                for subsub in glob.glob(sub+'/*.db'):\n",
    "                    if 'v2.0_10yrs.db' in subsub:\n",
    "                        dbases.append(subsub)\n",
    "            elif 'v2.0_10yrs.db' in sub:\n",
    "                dbases.append(sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5999ca-feff-480c-b44a-363c97e56afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateKNPopSlicer( n_events=10000, seed=42):\n",
    "    \"\"\" Generate a population of KNe events, and put the info about them\n",
    "    into a UserPointSlicer object\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_events : int (10000)\n",
    "        The number of kilonova events to generate\n",
    "    seed : float\n",
    "        The seed passed to np.random\n",
    "    \"\"\"\n",
    "\n",
    "    def rndm(a, b, g, size=1):\n",
    "        \"\"\"Power-law gen for pdf(x)\\propto x^{g-1} for a<=x<=b\"\"\"\n",
    "        r = np.random.random(size=size)\n",
    "        ag, bg = a**g, b**g\n",
    "        return (ag + (bg - ag)*r)**(1./g)\n",
    "\n",
    "    ra, dec = uniformSphere(n_events, seed=seed)\n",
    "    \n",
    "    # Define the distance\n",
    "    \n",
    "    # Set up the slicer to evaluate the catalog we just made\n",
    "    slicer = slicers.UserPointsSlicer(ra, dec, latLonDeg=True, badval=0)\n",
    "    return slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7189ee2f-e466-4ec8-ab34-a4bbc17a3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric42 = GRBKN_obs(metricName='GRBKN_obs42', data_path='./kn_newmodel_Alberto',obs_path='./obs_newmodel_Alberto_42', dist_Mpc = 42,save=False)\n",
    "metric100 = GRBKN_obs(metricName='GRBKN_obs100', data_path='./kn_newmodel_Alberto',obs_path='./obs_newmodel_Alberto_100', dist_Mpc = 100,save=False)\n",
    "metric300 = GRBKN_obs(metricName='GRBKN_obs300', data_path='./kn_newmodel_Alberto',obs_path='./obs_newmodel_Alberto_300', dist_Mpc = 300,save=False)\n",
    "\n",
    "# bundle\n",
    "sqlconstraint='note not like  \"DD%\"'\n",
    "# this is for the \"Targeted Search\"\n",
    "## coo={'ra':np.array([197.450341598]),'dec':np.array([-23.3814675445])}\n",
    "# this is for the \"All Sky Search\"\n",
    "slicer = generateKNPopSlicer(n_events = 500)\n",
    "Sky42 = metricBundles.MetricBundle(metric42, slicer, sqlconstraint)\n",
    "Sky100 = metricBundles.MetricBundle(metric100, slicer, sqlconstraint)\n",
    "Sky300 = metricBundles.MetricBundle(metric300, slicer, sqlconstraint)\n",
    "# group bundle\n",
    "bundleDict ={'GRBKN_obs42':Sky42,'GRBKN_obs100':Sky100,'GRBKN_obs300':Sky300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221e4c9d-7207-4cc2-bba8-0ed962c41f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4171cc-1526-4a91-9faf-7211dda1f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/126 [00:00<?, ?it/s]/data0/lsst_stack/stack/miniconda3-py38_4.9.2-0.4.2/Linux64/sims_maf/2.13.0.sims-93-g8bc2eb33+a14e41332a/python/lsst/sims/maf/db/opsimDatabase.py:46: UserWarning: Could not identify opsim database version; just using Database class instead\n",
      "  warnings.warn('Could not identify opsim database version; just using Database class instead')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying database observations with constraint note not like  \"DD%\" for columns ['observationStartMJD', 'fiveSigmaDepth', 'fieldRA', 'fieldDec', 'night', 'visitTime', 'visitExposureTime', 'filter']\n",
      "Found 1992714 visits\n",
      "Running:  ['GRBKN_obs42']\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3c6abeebe167>:175: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  T0 = lcs['T0'][:,None] + self.mjd0 + ulcNumber*lcs['transDuration'].to_numpy()[:,None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.375766293488209\n",
      "0\n",
      "7.681459069876592\n",
      "0\n",
      "5.34965153712658\n",
      "0\n",
      "4.7027541960461\n",
      "0\n",
      "4.378141321834437\n",
      "0\n",
      "5.611488510831731\n",
      "0\n",
      "8.606685625251965\n",
      "0\n",
      "7.4549151772282505\n",
      "0\n",
      "6.754345407471848\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3c6abeebe167>:212: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  res = ndet/nobj['detected'][0]/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/126 [50:36<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for dbs in tqdm(dbases):\n",
    "    opsdb = db.OpsimDatabase(dbs)\n",
    "    #for k, (sim, obs) in enumerate(zip([],['./obs_newmodel_Alberto'])): #enumerate(zip(['./sim_knlc_46p48Mpc','./sim_knlc_100Mpc','./sim_knlc_300Mpc'],['./obs_lc_wfd_knlcv2.99_46p48Mpc_noDD','./obs_lc_wfd_knlcv2.99_100Mpc_noDD','./obs_lc_wfd_knlcv2.99_300Mpc_noDD'])):        \n",
    "    Sky42.setRunName(dbs)\n",
    "    Sky100.setRunName(dbs)\n",
    "    Sky300.setRunName(dbs)\n",
    "    group = metricBundles.MetricBundleGroup(bundleDict, opsdb, outDir = outDir, resultsDb=resultsDb, dbTable='observations',)\n",
    "    # run\n",
    "    group.runAll()\n",
    "t = time.time()-start\n",
    "print('time:{} min'.format(t/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
